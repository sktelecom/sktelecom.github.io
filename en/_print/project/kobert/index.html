<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js data-theme-init><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=color-scheme content="light dark"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#000000"><style>html{background:Canvas;color:CanvasText}@media(prefers-color-scheme:dark){html{background:#0b0d12;color:#e6e6e6}}html[data-theme-init] *{transition:none!important}</style><script>(function(){const t="td-color-theme",n=localStorage.getItem(t);let e=n||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");e==="auto"&&(e=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-bs-theme",e)})()</script><link rel=canonical type=text/html href=https://sktelecom.github.io/en/project/kobert/><link rel=alternate type=application/rss+xml href=https://sktelecom.github.io/en/project/kobert/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>KoBERT | Open Source</title><meta name=description content="Korean BERT pre-trained model (Korean BERT pre-trained cased)"><meta property="og:url" content="https://sktelecom.github.io/en/project/kobert/"><meta property="og:site_name" content="Open Source"><meta property="og:title" content="KoBERT"><meta property="og:description" content="Korean BERT pre-trained model (Korean BERT pre-trained cased)"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="KoBERT"><meta itemprop=description content="Korean BERT pre-trained model (Korean BERT pre-trained cased)"><meta itemprop=dateModified content="2025-12-31T17:28:39+09:00"><meta itemprop=wordCount content="467"><meta name=twitter:card content="summary"><meta name=twitter:title content="KoBERT"><meta name=twitter:description content="Korean BERT pre-trained model (Korean BERT pre-trained cased)"><link rel=preload href=/scss/main.min.08d5ae6532f6ce8028e5ebcd15f74b7c4b4c24c2d1b496c7f3b7869f6e4de801.css as=style integrity="sha256-CNWuZTL2zoAo5evNFfdLfEtMJMLRtJbH87eGn25N6AE=" crossorigin=anonymous><link href=/scss/main.min.08d5ae6532f6ce8028e5ebcd15f74b7c4b4c24c2d1b496c7f3b7869f6e4de801.css rel=stylesheet integrity="sha256-CNWuZTL2zoAo5evNFfdLfEtMJMLRtJbH87eGn25N6AE=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="td-navbar-container container-fluid flex-column flex-md-row"><a class=navbar-brand href=/en/><span class="navbar-brand__logo navbar-logo"><svg width="92" height="37" viewBox="0 0 92 37" fill="none"><path d="M89.2452 27.2679C87.4443 27.2679 86.5176 28.4541 86.3735 28.6343 85.9184 27.7758 85.0834 27.2679 83.9865 27.2679 82.4017 27.2679 81.4979 28.1887 81.3506 28.3394 81.2851 28.0937 80.9609 27.4187 79.936 27.4187 79.6413 27.4187 79.2058 27.5137 79.1731 27.5202 79.2157 27.7136 79.4089 28.6507 79.4089 29.9451v5.6983h2.0825V29.8336C81.5339 29.7976 82.3133 29.0079 83.2497 29.0079 84.1862 29.0079 84.6545 29.7091 84.6545 30.666v4.9774H86.7468V29.8336C86.7894 29.7943 87.5523 29.0079 88.5052 29.0079c.952799999999996.0 1.3916.7012 1.3916 1.6581v4.9774H91.999V30.3383C91.999 28.4771 90.9413 27.2646 89.2419 27.2646L89.2452 27.2679z" fill="#FF7A00"/><path d="M66.3954 34.1426c-1.4178.0-2.4263-1.1206-2.4263-2.5854.0-1.6318 1.1493-2.6017 2.4263-2.6017C67.0863 28.9555 67.3744 29.1652 67.8296 29.1652 68.3175 29.1652 68.5761 28.9293 68.8185 28.4574 68.9527 28.1985 69.0313 28.0478 69.0313 28.0478 68.9265 27.9823 67.8722 27.2646 66.0778 27.2646c-2.6294.0-4.2011 1.8842-4.2011 4.2894.0 2.6247 1.7977 4.2729 4.2011 4.2729C67.8198 35.8269 68.8741 35.1158 69.0608 34.9815L68.3371 33.5528C68.1767 33.6544 67.4334 34.1361 66.3921 34.1361L66.3954 34.1426z" fill="#FF7A00"/><path d="M43.5226 27.2715C41.5252 27.2715 39.8389 28.8968 39.8389 31.5608s1.6339 4.2729 4.0766 4.2729C45.8572 35.8337 46.8625 34.985 46.9836 34.9064c0 0-.189900000000002-.308-.2423-.3932C46.4695 34.0675 46.1585 33.9234 45.8147 33.9234 45.127 33.9234 45.0386 34.2084 44.1087 34.2084c-1.5979.0-2.1513-1.2484-2.1906-2.0807h5.3504V31.5084C47.2685 28.9558 45.7983 27.2715 43.5226 27.2715zm-1.6078 3.3751C41.9148 29.7094 42.573 28.8411 43.4931 28.8411 44.5245 28.8411 45.091 29.7356 45.1074 30.6466H41.9148z" fill="#FF7A00"/><path d="M50.8473 33.3461v-8.536c0-.9634-.641799999999996-1.7105-1.6405-1.7105H48.7615V34.1817c0 1.0191.631900000000002 1.6548 1.7289 1.6548 1.3523.0 1.7583-.9634 1.7583-1.8711C52.1931 33.9949 51.9049 34.1129 51.6168 34.1129 51.1354 34.1129 50.8473 33.8311 50.8473 33.3461z" fill="#FF7A00"/><path d="M36.9038 33.0531v-4.06h1.7453L39.2548 27.4236H36.9038V24.9692S36.7172 24.9692 36.7106 24.9692c-.929899999999996.0-1.8893.3933-1.8893 2.4347V27.4236H33.2791v1.5695h1.5422V33.774c0 1.3533.799 2.0578 1.9352 2.0578C37.6733 35.8318 38.8586 35.5533 38.8586 33.7346 38.7866 33.7772 38.3413 34.0656 37.8534 34.0656 37.1756 34.0656 36.9071 33.6527 36.9071 33.0531H36.9038z" fill="#FF7A00"/><path d="M56.6146 27.2715C54.6172 27.2715 52.9309 28.8968 52.9309 31.5608s1.6339 4.2729 4.0766 4.2729C58.9493 35.8337 59.9545 34.985 60.0757 34.9064c0 0-.189899999999994-.308-.2423-.3932C59.5616 34.0675 59.2505 33.9234 58.9067 33.9234 58.2191 33.9234 58.1307 34.2084 57.2007 34.2084c-1.5979.0-2.1513-1.2484-2.1905-2.0807h5.3503V31.5084c0-2.5526-1.4702-4.2369-3.7459-4.2369zm-1.611 3.3751C55.0036 29.7094 55.6618 28.8411 56.5819 28.8411 57.6133 28.8411 58.1798 29.7356 58.1962 30.6466H55.0036z" fill="#FF7A00"/><path d="M73.84 35.8297C71.2859 35.8297 69.7502 34.1421 69.7502 31.5502S71.2663 27.2642 73.84 27.2642s4.093 1.7039 4.093 4.286c0 2.4412-1.3982 4.2795-4.093 4.2795zm0-1.6056c1.2803.0 2.017-1.101 2.017-2.6706S75.1366 28.8731 73.84 28.8731c-1.2967.0-2.0138 1.0911-2.0138 2.6804C71.8262 33.1427 72.5466 34.2241 73.84 34.2241z" fill="#FF7A00"/><path d="M6.66015 26.516C5.3995 25.9262 4.36806 25.4511 4.36806 24.4877c0-.737300000000001.5894-1.2714 1.75181-1.2714C6.54882 23.2163 6.89591 23.2655 7.25937 23.3343 7.44928 23.3671 7.64902 23.3933 7.81601 23.3933 8.83108 23.3933 9.4041 22.7871 9.78721 21.6369L9.94438 21.1683C9.78066 21.1028 8.12381 20.3721 5.95942 20.3721c-3.4414.0-5.258696 2.2085-5.258696 4.499.0 1.1567.360186 1.9923.926656 2.6542C2.35757 28.374 3.39556 28.931 4.37134 29.4029 5.78916 30.0976 7.06945 30.612 7.06945 31.6475c0 .914200000000001-.9463 1.4352-2.21023 1.4352C3.12706 33.0827 1.61428 32.0931 1.42109 31.9719L0 34.6392C.252129 34.7834 2.0858 35.9466 5.09826 35.9466c3.21219.0 5.64504-1.8448 5.64504-4.6792S8.48727 27.4008 6.66342 26.516H6.66015z" fill="#EA002C"/><path d="M19.2195 27.835l5.8252-7.1499H20.8928l-4.6464 6.1701H16.1776V20.6851H12.7559V35.8304H12.9589c1.48.0 3.2416-.684899999999999 3.2416-3.1589V29.1949H16.2693l4.7381 6.4454h4.3549L19.2195 27.835z" fill="#EA002C"/><path d="M25.2373 4.47314c-1.205.2261-2.9896 1.32055-2.9863 3.25713C22.2543 9.48663 23.6918 10.5516 23.695 12.8552 23.7016 14.5886 22.7487 15.7551 21.7173 16.4006 22.1331 16.3646 22.5916 16.3384 23.0925 16.3384 24.1469 16.3384 24.7821 16.4367 24.8214 16.4432l5.4061-6.63545c-1.4997-2.24787-3.2548-3.9944-4.9902-5.33461z" fill="#EA002C"/><path d="M29.7848 22.392C30.4659 21.3336 30.551 19.6428 30.61 17.9225 30.6722 16.3168 31.0095 15.111 33.1542 15.1012 33.629 15.1012 34.0809 15.1634 34.9027 15.1634 38.0462 15.1503 40.0992 14.0657 41.373 13.3546 38.7665 11.69 34.9584 9.99265 30.2367 9.79932c-.3078.86838-2.7014 7.52678-2.8815 8.06748C27.3814 17.8995 27.8005 18.3681 28.3244 19.2856c.7728 1.2583 1.1854 2.3265 1.4604 3.1064z" fill="#EA002C"/><path d="M18.3809 16.9495C18.1092 16.9495 17.9716 16.7692 17.9356 16.4547 17.8996 16.1434 16.5506 3.76696 16.3475 1.89263 16.3181 1.62066 16.2493 1.11604 16.2493.939089 16.246.650732 16.436.5 16.6553.5c.6418.0 4.1323.81592 7.8357 3.41441-1.0675.30147-2.9961 1.4123-2.9895 3.7126C21.508 9.66189 22.9651 10.7826 22.9717 12.824 22.9848 16.1467 19.1668 16.9495 18.3777 16.9495H18.3809z" fill="#FF7A00"/><path d="M30.0969 23.2761C30.1559 23.4301 30.2083 23.5612 30.2639 23.6496 30.3491 23.7938 30.4604 23.8593 30.5979 23.8593 30.683 23.8593 30.7911 23.8299 30.9057 23.7774c.2849-.131 11.5718-5.3903 13.2745-6.1734C44.4257 17.486 44.894 17.2763 45.0479 17.1845 45.2083 17.0928 45.2804 16.9617 45.2804 16.8241 45.2804 16.7487 45.2574 16.6734 45.2149 16.6013 45.002 16.2572 43.9117 15.0972 42.0845 13.8291c-1.4505.7995-3.7131 2.0349-7.0792 2.048C34.1801 15.8771 33.9935 15.8214 33.4303 15.8247 31.7865 15.8312 31.3772 16.5325 31.315 17.9742 31.3052 18.2462 31.3019 18.6132 31.2855 19.0163 31.2331 20.304 31.0825 22.0833 30.0969 23.2728V23.2761z" fill="#FF7A00"/></svg></span><span class=navbar-brand__name>Open Source</span></a><div class="td-navbar-nav-scroll td-navbar-nav-scroll--indicator" id=main_navbar><div class="scroll-indicator scroll-left"></div><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/en/about/><span>About</span></a></li><li class=nav-item><a class="nav-link active" href=/en/project/><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/en/guide/><span>Guide</span></a></li><li class=nav-item><a class=nav-link href=/en/compliance/><span>Compliance</span></a></li><li class=nav-item><a class=nav-link href=/en/blog/><span>Blog</span></a></li><li class="nav-item td-navbar__lang-menu"><div class="td-lang-menu dropdown"><a class="nav-link dropdown-toggle td-lang-menu__title" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><span class=td-lang-menu__title-text>English</span>
<span class=td-lang-menu__title-code>EN</span></a><ul class=dropdown-menu><li><span class="dropdown-item active">English</span></li><li><a class=dropdown-item href=/project/kobert/>한국어</a></li></ul></div></li><li class="nav-item td-navbar__light-dark-menu"><div class="td-light-dark-menu dropdown"><svg class="d-none"><symbol id="check2" viewBox="0 0 16 16"><path d="M13.854 3.646a.5.5.0 010 .708l-7 7a.5.5.0 01-.708.0l-3.5-3.5a.5.5.0 11.708-.708L6.5 10.293l6.646-6.647a.5.5.0 01.708.0z"/></symbol><symbol id="circle-half" viewBox="0 0 16 16"><path d="M8 15A7 7 0 108 1v14zm0 1A8 8 0 118 0a8 8 0 010 16z"/></symbol><symbol id="moon-stars-fill" viewBox="0 0 16 16"><path d="M6 .278a.768.768.0 01.08.858 7.208 7.208.0 00-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527.0 1.04-.055 1.533-.16a.787.787.0 01.81.316.733.733.0 01-.031.893A8.349 8.349.0 018.344 16C3.734 16 0 12.286.0 7.71.0 4.266 2.114 1.312 5.124.06A.752.752.0 016 .278z"/><path d="M10.794 3.148a.217.217.0 01.412.0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217.0 010 .412l-1.162.387A1.734 1.734.0 0011.593 7.69l-.387 1.162a.217.217.0 01-.412.0l-.387-1.162A1.734 1.734.0 009.31 6.593l-1.162-.387a.217.217.0 010-.412l1.162-.387a1.734 1.734.0 001.097-1.097l.387-1.162zM13.863.099a.145.145.0 01.274.0l.258.774c.115.346.386.617.732.732l.774.258a.145.145.0 010 .274l-.774.258a1.156 1.156.0 00-.732.732l-.258.774a.145.145.0 01-.274.0l-.258-.774a1.156 1.156.0 00-.732-.732l-.774-.258a.145.145.0 010-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"/></symbol><symbol id="sun-fill" viewBox="0 0 16 16"><path d="M8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 0zm0 13a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 13zm8-5a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2a.5.5.0 01.5.5zM3 8a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2A.5.5.0 013 8zm10.657-5.657a.5.5.0 010 .707l-1.414 1.415a.5.5.0 11-.707-.708l1.414-1.414a.5.5.0 01.707.0zm-9.193 9.193a.5.5.0 010 .707L3.05 13.657a.5.5.0 01-.707-.707l1.414-1.414a.5.5.0 01.707.0zm9.193 2.121a.5.5.0 01-.707.0l-1.414-1.414a.5.5.0 01.707-.707l1.414 1.414a.5.5.0 010 .707zM4.464 4.465a.5.5.0 01-.707.0L2.343 3.05a.5.5.0 11.707-.707l1.414 1.414a.5.5.0 010 .708z"/></symbol></svg>
<button class="btn btn-link nav-link dropdown-toggle d-flex align-items-center" id=bd-theme type=button aria-expanded=false data-bs-toggle=dropdown aria-label="Toggle theme (auto)">
<svg class="bi my-1 theme-icon-active"><use href="#circle-half"/></svg></button><ul class=dropdown-menu aria-labelledby=bd-theme><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=light aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#sun-fill"/></svg>
Light
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=dark aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#moon-stars-fill"/></svg>
Dark
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center active" data-bs-theme-value=auto aria-pressed=true>
<svg class="bi me-2 opacity-50"><use href="#circle-half"/></svg>
Auto
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li></ul></div></li></ul><div class="scroll-indicator scroll-right"></div></div><div class="d-none d-lg-block td-navbar__search"><div class=td-search><div class=td-search__icon></div><input type=search class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/en/project/kobert/>Return to the regular view of this page</a>.</p></div><h1 class=title>KoBERT</h1><div class=lead>Korean BERT pre-trained model (Korean BERT pre-trained cased)</div><ul></ul><div class=content><p><img src=/en/project/kobert/kobert.jpg alt=KoBERT></p><p>KoBERT is a Korean-specialized BERT model developed by SK Telecom to overcome the limitations of Google&rsquo;s publicly released BERT language model in processing Korean.</p><h2 id=project-information>Project Information<a class=td-heading-self-link href=#project-information aria-label="Heading self-link"></a></h2><ul><li>Developer: SK Telecom T-Brain (formerly SKT AI Center)</li><li>License: Apache License 2.0</li><li>GitHub: <a href=https://github.com/SKTBrain/KoBERT>https://github.com/SKTBrain/KoBERT</a></li></ul><h2 id=key-features>Key Features<a class=td-heading-self-link href=#key-features aria-label="Heading self-link"></a></h2><h3 id=1-korean-language-optimization>1. Korean Language Optimization<a class=td-heading-self-link href=#1-korean-language-optimization aria-label="Heading self-link"></a></h3><ul><li>Trained on millions of Korean sentences collected from Wikipedia and news sources</li><li>Large-scale Korean language corpus utilization</li><li>Reflects irregular Korean language variation characteristics</li></ul><h3 id=2-efficient-tokenization>2. Efficient Tokenization<a class=td-heading-self-link href=#2-efficient-tokenization aria-label="Heading self-link"></a></h3><ul><li>Data-driven tokenization technique</li><li>27% fewer tokens with over 2.6% performance improvement compared to existing methods</li><li>Subword segmentation tailored to Korean language characteristics</li></ul><h3 id=3-distributed-learning-technology>3. Distributed Learning Technology<a class=td-heading-self-link href=#3-distributed-learning-technology aria-label="Heading self-link"></a></h3><ul><li>Ring-reduce based distributed learning technique</li><li>Fast training of over a billion sentences across multiple machines</li><li>Efficient processing of large-scale data</li></ul><h3 id=4-multi-framework-support>4. Multi-framework Support<a class=td-heading-self-link href=#4-multi-framework-support aria-label="Heading self-link"></a></h3><ul><li>PyTorch</li><li>TensorFlow</li><li>ONNX</li><li>MXNet</li></ul><h2 id=applications>Applications<a class=td-heading-self-link href=#applications aria-label="Heading self-link"></a></h2><h3 id=sk-telecom-internal-usage>SK Telecom Internal Usage<a class=td-heading-self-link href=#sk-telecom-internal-usage aria-label="Heading self-link"></a></h3><ol><li>Call center chatbots - Improving customer service efficiency</li><li>AI legal/patent search service - Document search and analysis</li><li>Machine Reading Comprehension (MRC) - Extracting accurate answers from marketing materials</li><li>Context-based document vector generation - Similar document recommendations (patent applications)</li></ol><h3 id=general-use-cases>General Use Cases<a class=td-heading-self-link href=#general-use-cases aria-label="Heading self-link"></a></h3><ul><li>Sentiment Analysis</li><li>Named Entity Recognition (NER)</li><li>Text Classification</li><li>Question Answering Systems</li><li>Sentence Similarity Measurement</li><li>Text Embedding Generation</li></ul><h2 id=installation-and-usage>Installation and Usage<a class=td-heading-self-link href=#installation-and-usage aria-label="Heading self-link"></a></h2><h3 id=installation>Installation<a class=td-heading-self-link href=#installation aria-label="Heading self-link"></a></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install kobert-transformers
</span></span><span style=display:flex><span>pip install transformers
</span></span></code></pre></div><h3 id=basic-usage>Basic Usage<a class=td-heading-self-link href=#basic-usage aria-label="Heading self-link"></a></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>kobert_transformers</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>get_tokenizer</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>transformers</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>BertModel</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Load tokenizer and model</span>
</span></span><span style=display:flex><span><span style=color:#000>tokenizer</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>get_tokenizer</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#000>model</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>BertModel</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>from_pretrained</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;skt/kobert-base-v1&#39;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Tokenize and generate embeddings</span>
</span></span><span style=display:flex><span><span style=color:#000>text</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;Korean natural language processing is fascinating&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>inputs</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>tokenizer</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>text</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>return_tensors</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;pt&#39;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#000>outputs</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>model</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>inputs</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Extract sentence embedding</span>
</span></span><span style=display:flex><span><span style=color:#000>sentence_embedding</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>outputs</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>last_hidden_state</span><span style=color:#000;font-weight:700>[:,</span> <span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000;font-weight:700>:]</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>squeeze</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#204a87>print</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>sentence_embedding</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>shape</span><span style=color:#000;font-weight:700>)</span>  <span style=color:#8f5902;font-style:italic># torch.Size([768])</span>
</span></span></code></pre></div><h3 id=pytorch-example>PyTorch Example<a class=td-heading-self-link href=#pytorch-example aria-label="Heading self-link"></a></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>torch</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>kobert_transformers</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>get_kobert_model</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>get_tokenizer</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Load model and tokenizer</span>
</span></span><span style=display:flex><span><span style=color:#000>tokenizer</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>get_tokenizer</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#000>model</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>get_kobert_model</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Process text</span>
</span></span><span style=display:flex><span><span style=color:#000>text</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;KoBERT is specialized in Korean language understanding.&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>encoded</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>tokenizer</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>encode_plus</span><span style=color:#000;font-weight:700>(</span>
</span></span><span style=display:flex><span>    <span style=color:#000>text</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#000>add_special_tokens</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#000>max_length</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>128</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#000>padding</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;max_length&#39;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#000>return_attention_mask</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#000>return_tensors</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;pt&#39;</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Model inference</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>with</span> <span style=color:#000>torch</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>no_grad</span><span style=color:#000;font-weight:700>():</span>
</span></span><span style=display:flex><span>    <span style=color:#000>outputs</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>model</span><span style=color:#000;font-weight:700>(</span>
</span></span><span style=display:flex><span>        <span style=color:#000>input_ids</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>encoded</span><span style=color:#000;font-weight:700>[</span><span style=color:#4e9a06>&#39;input_ids&#39;</span><span style=color:#000;font-weight:700>],</span>
</span></span><span style=display:flex><span>        <span style=color:#000>attention_mask</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>encoded</span><span style=color:#000;font-weight:700>[</span><span style=color:#4e9a06>&#39;attention_mask&#39;</span><span style=color:#000;font-weight:700>]</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#000>pooled_output</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>outputs</span><span style=color:#000;font-weight:700>[</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>]</span>  <span style=color:#8f5902;font-style:italic># [CLS] token output</span>
</span></span><span style=display:flex><span><span style=color:#204a87>print</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>pooled_output</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>shape</span><span style=color:#000;font-weight:700>)</span>  <span style=color:#8f5902;font-style:italic># torch.Size([1, 768])</span>
</span></span></code></pre></div><h2 id=performance-benchmarks>Performance Benchmarks<a class=td-heading-self-link href=#performance-benchmarks aria-label="Heading self-link"></a></h2><table><thead><tr><th>Task</th><th>Dataset</th><th>KoBERT Score</th><th>Baseline</th></tr></thead><tbody><tr><td>Sentiment Analysis</td><td>NSMC</td><td>89.63%</td><td>87.42%</td></tr><tr><td>NER</td><td>Korean NER</td><td>86.11%</td><td>84.13%</td></tr><tr><td>Sentence Similarity</td><td>KorSTS</td><td>81.59%</td><td>77.92%</td></tr><tr><td>Question Answering</td><td>KorQuAD 1.0</td><td>52.81 (EM)</td><td>48.42</td></tr></tbody></table><h2 id=model-specifications>Model Specifications<a class=td-heading-self-link href=#model-specifications aria-label="Heading self-link"></a></h2><ul><li>Architecture: BERT-base</li><li>Vocabulary Size: 8,002</li><li>Hidden Size: 768</li><li>Number of Layers: 12</li><li>Number of Attention Heads: 12</li><li>Intermediate Size: 3,072</li><li>Max Sequence Length: 512</li></ul><h2 id=community-and-support>Community and Support<a class=td-heading-self-link href=#community-and-support aria-label="Heading self-link"></a></h2><h3 id=technical-support>Technical Support<a class=td-heading-self-link href=#technical-support aria-label="Heading self-link"></a></h3><ul><li>GitHub Issues: <a href=https://github.com/SKTBrain/KoBERT/issues>https://github.com/SKTBrain/KoBERT/issues</a></li><li>Active community contributions</li><li>Continuous model updates</li></ul><h3 id=related-projects>Related Projects<a class=td-heading-self-link href=#related-projects aria-label="Heading self-link"></a></h3><ul><li><a href=/en/project/kogpt2/>KoGPT2</a> - Korean GPT-2 model</li><li><a href=/en/project/kobart/>KoBART</a> - Korean BART model</li><li><a href=../ax-llm/>A.X LLM</a> - Latest Korean LLM</li></ul><h2 id=using-on-hugging-face>Using on Hugging Face<a class=td-heading-self-link href=#using-on-hugging-face aria-label="Heading self-link"></a></h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>transformers</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>AutoModel</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>AutoTokenizer</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Load directly from Hugging Face Hub</span>
</span></span><span style=display:flex><span><span style=color:#000>model_name</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;skt/kobert-base-v1&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>tokenizer</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>AutoTokenizer</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>from_pretrained</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>model_name</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#000>model</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>AutoModel</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>from_pretrained</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>model_name</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Inference</span>
</span></span><span style=display:flex><span><span style=color:#000>text</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;KoBERT is the standard for Korean natural language processing&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>inputs</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>tokenizer</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>text</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>return_tensors</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;pt&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#000>outputs</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>model</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>inputs</span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div><h2 id=license>License<a class=td-heading-self-link href=#license aria-label="Heading self-link"></a></h2><p>Apache License 2.0 - Commercial use allowed</p><h2 id=resources>Resources<a class=td-heading-self-link href=#resources aria-label="Heading self-link"></a></h2><ul><li>GitHub: <a href=https://github.com/SKTBrain/KoBERT>https://github.com/SKTBrain/KoBERT</a></li><li>Hugging Face: <a href=https://huggingface.co/skt/kobert-base-v1>skt/kobert-base-v1</a></li><li>Documentation: <a href=https://github.com/SKTBrain/KoBERT/blob/master/README.md>GitHub README</a></li><li>Issues: <a href=https://github.com/SKTBrain/KoBERT/issues>GitHub Issues</a></li></ul></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="User mailing list" aria-label="User mailing list"><a target=_blank rel=noopener href=mailto:opensource@sktelecom.com aria-label="User mailing list"><i class="fa fa-envelope"></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/sktelecom aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2020&ndash;2026
<span class=td-footer__authors>SK Telecom | <a href=https://creativecommons.org/licenses/by/4.0>CC BY 4.0</a> |</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span><span class=ms-2><a href=https://privacy.sktelecom.com/ target=_blank rel=noopener>Privacy Policy</a></span></div></div></div></footer></div><script src=/js/main.min.fa59819d93e50d4c9cf0835cb09777122fa07fe27d63d73a581d64139f6697c2.js integrity="sha256-+lmBnZPlDUyc8INcsJd3Ei+gf+J9Y9c6WB1kE59ml8I=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>